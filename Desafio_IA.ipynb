{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio IA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZdTjZIR4q9HIfYQv7Aq4S7Y-bYyU4bcO",
      "authorship_tag": "ABX9TyNkQaS9Sv2g//H5deKsxR6Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wyllton/phyton/blob/master/Desafio_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_9j4Nw2eazI"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import zipfile\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras.layers import Conv2D, Activation, MaxPooling2D, Dense, Flatten, Dropout,BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import model_from_json\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP7J0JysgCXR"
      },
      "source": [
        "path = '/content/drive/My Drive/archive.zip'\n",
        "zip = zipfile.ZipFile(file = path, mode = 'r')\n",
        "zip.extractall('./')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_oOKAy8gX-K"
      },
      "source": [
        "categorias = {'01_palm' : 0 , '02_l' : 1 , '03_fist' : 2 , '04_fist_moved': 3 , '05_thumb': 4, '06_index' : 5\n",
        "              , '07_ok': 6, '08_palm_moved': 7 , '09_c': 8 , '10_down': 9}\n",
        "img_size = 150"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGeUDsxHjbBT"
      },
      "source": [
        "x_dados=[]\n",
        "y_dados = []\n",
        "num_fotos = 0\n",
        "path = \"/content/leapgestrecog/leapGestRecog/0\"\n",
        "for i in range (0, len(categorias)):\n",
        "  for j in os.listdir(path + str(i) + '/' ):\n",
        "    if not j.startswith('.'):\n",
        "      count = 0\n",
        "      for k in os.listdir(path + str(i) + '/' + j + '/'):\n",
        "        img = cv2.imread(path + str(i) + '/' + j +'/' + k)\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "        arr = np.array(img)\n",
        "        x_dados.append(arr)\n",
        "        count = count + 1\n",
        "      y_valor = np.full((count, 1), categorias[j])\n",
        "      y_dados.append(y_valor)\n",
        "      num_fotos = num_fotos + count\n",
        "x_dados = np.array(x_dados, dtype='float32')\n",
        "x_dados = x_dados / 255\n",
        "y_dados = np.array(y_dados)\n",
        "y_dados = y_dados.reshape(num_fotos, 1)\n",
        "y_dados = keras.utils.to_categorical(y_dados)\n",
        "\n",
        "      "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Eaec3nBoEa",
        "outputId": "a8a398a8-b06d-4464-cee2-1f4695c0e48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_dados = x_dados.reshape((num_fotos, img_size, img_size, 1))\n",
        "x_dados.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 150, 150, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDoYqdUvc_oM"
      },
      "source": [
        "x_treino, x_teste , y_treino , y_teste = train_test_split(x_dados, y_dados, test_size = 0.2, random_state = 45)\n",
        "_, x_val, _ , y_val = train_test_split(x_treino, y_treino , test_size = 0.2, random_state = 43)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inyVBJ3zfrSR",
        "outputId": "6a460f37-976b-4a7e-abad-5206ae2c6b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "num_features = 32\n",
        "num_labels = 10\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "modelo = Sequential()\n",
        "\n",
        "modelo.add(Conv2D(num_features, kernel_size= (5,5), activation= 'relu', \n",
        "                 input_shape =(img_size, img_size , 1), kernel_regularizer = l2(0.01),padding='same'))\n",
        "modelo.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\n",
        "\n",
        "modelo.add(Conv2D(2*num_features, kernel_size = (3,3), activation= 'relu', padding='same'))\n",
        "modelo.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\n",
        "\n",
        "modelo.add(Conv2D(2*2*num_features, kernel_size = (3,3), activation= 'relu', padding='same'))\n",
        "modelo.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "modelo.add(Flatten())\n",
        "\n",
        "modelo.add(Dense(2*2*num_features, activation= 'relu'))\n",
        "modelo.add(Dense(num_labels, activation= 'softmax'))\n",
        "\n",
        "modelo.summary()\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 150, 150, 32)      832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 75, 75, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 37, 37, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 41472)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               5308544   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 5,403,018\n",
            "Trainable params: 5,403,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcb1bzN4hodn"
      },
      "source": [
        "modelo.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = Adam(lr = 0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "arquivo_modelo = \"modelo_01_DesafioIA.h5\"\n",
        "arquivo_modelo_json = \"modelo_01_DesafioIa.json\"\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.9 , patience=3, verbose= 1)\n",
        "\n",
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta= 0, patience = 4, verbose=1 )\n",
        "\n",
        "checkpointer = ModelCheckpoint(arquivo_modelo, monitor = 'val_loss', verbose = 1, \n",
        "                               save_best_only= True)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrj18AyP8XA6"
      },
      "source": [
        "modelo_json = modelo.to_json()\n",
        "with open(arquivo_modelo_json, 'w') as json_file:\n",
        "  json_file.write(modelo_json)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVw7bYGC9vEO",
        "outputId": "304d4fc4-7b51-4369-86e3-bc9046773c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "history = modelo.fit(x_treino,y_treino,\n",
        "                     batch_size = batch_size,\n",
        "                     epochs = epochs, verbose = 1,\n",
        "                     validation_data = (x_val, y_val),shuffle = True,\n",
        "                     callbacks = [lr_reducer, early_stopper, checkpointer])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.9243\n",
            "Epoch 00001: val_loss improved from inf to 0.02310, saving model to modelo_01_expressões.h5\n",
            "250/250 [==============================] - 626s 3s/step - loss: 0.2511 - accuracy: 0.9243 - val_loss: 0.0231 - val_accuracy: 0.9975\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9975\n",
            "Epoch 00002: val_loss improved from 0.02310 to 0.01399, saving model to modelo_01_expressões.h5\n",
            "250/250 [==============================] - 627s 3s/step - loss: 0.0229 - accuracy: 0.9975 - val_loss: 0.0140 - val_accuracy: 0.9994\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9998\n",
            "Epoch 00003: val_loss improved from 0.01399 to 0.00899, saving model to modelo_01_expressões.h5\n",
            "250/250 [==============================] - 628s 3s/step - loss: 0.0115 - accuracy: 0.9998 - val_loss: 0.0090 - val_accuracy: 0.9997\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 00004: val_loss improved from 0.00899 to 0.00558, saving model to modelo_01_expressões.h5\n",
            "250/250 [==============================] - 630s 3s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 00005: val_loss improved from 0.00558 to 0.00344, saving model to modelo_01_expressões.h5\n",
            "250/250 [==============================] - 631s 3s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 00006: val_loss improved from 0.00344 to 0.00214, saving model to modelo_01_expressões.h5\n",
            "250/250 [==============================] - 635s 3s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 00007: val_loss improved from 0.00214 to 0.00158, saving model to modelo_01_expressões.h5\n",
            "250/250 [==============================] - 641s 3s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9923\n",
            "Epoch 00008: val_loss did not improve from 0.00158\n",
            "250/250 [==============================] - 628s 3s/step - loss: 0.0311 - accuracy: 0.9923 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9998\n",
            "Epoch 00009: val_loss did not improve from 0.00158\n",
            "250/250 [==============================] - 623s 2s/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00158\n",
            "250/250 [==============================] - 626s 3s/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqWzdVzIaT-e"
      },
      "source": [
        "modelo.save('modelo_01_DesafioIA.h5')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZUtyPdeafKI",
        "outputId": "40f93661-63a9-49f1-ce29-afce25321a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tLoss, tAccuracy = modelo.evaluate(x_teste, y_teste)\n",
        "print('Teste Accuracy: {:2.2f}%'.format(tAccuracy*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 41s 331ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Teste Accuracy: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0HQy3Ejaz3R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}